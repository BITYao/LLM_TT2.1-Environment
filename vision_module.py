"""
è§†è§‰æ„ŸçŸ¥æ¨¡å— - Telloæ‘„åƒå¤´ + ç™¾åº¦å›¾åƒè¯†åˆ«
"""
import cv2
import os
import time
import threading
from datetime import datetime
from baidu_vision import BaiduVision
from llm_client import LLMClient
from speech_synthesis import SpeechSynthesis
from config import VISION_AUTO_DESCRIPTION

class VisionModule:
    def __init__(self, tello):
        self.tello = tello
        self.baidu_vision = BaiduVision()
        self.llm_client = LLMClient()
        self.speech_synthesis = SpeechSynthesis()
        
        # æ‘„åƒå¤´ç›¸å…³
        self.frame_read = None
        self.video_streaming = False
        self.capture_folder = "picturecap"
        
        # è¯†åˆ«ç›¸å…³
        self.auto_recognition = False
        self.recognition_interval = 5.0  # è‡ªåŠ¨è¯†åˆ«é—´éš”ï¼ˆç§’ï¼‰
        self.last_recognition_time = 0
        self.latest_recognition_result = None
        
        # çº¿ç¨‹æ§åˆ¶
        self.recognition_thread = None
        self.recognition_running = False
        
        # æ™ºèƒ½æè¿°ç›¸å…³
        self.auto_description_enabled = VISION_AUTO_DESCRIPTION
        
        # åˆ›å»ºå›¾ç‰‡ä¿å­˜æ–‡ä»¶å¤¹
        self._ensure_capture_folder()
        
        print("âœ… è§†è§‰æ„ŸçŸ¥æ¨¡å—å·²åˆå§‹åŒ–")
        print(f"   è‡ªåŠ¨æè¿°æ’­æŠ¥: {'å¼€å¯' if self.auto_description_enabled else 'å…³é—­'}")
    
    def _ensure_capture_folder(self):
        """ç¡®ä¿å›¾ç‰‡ä¿å­˜æ–‡ä»¶å¤¹å­˜åœ¨"""
        if not os.path.exists(self.capture_folder):
            os.makedirs(self.capture_folder)
            print(f"ğŸ“ åˆ›å»ºå›¾ç‰‡ä¿å­˜æ–‡ä»¶å¤¹: {self.capture_folder}")
    
    def start_video_stream(self):
        """å¯åŠ¨è§†é¢‘æµï¼ˆé€‚é…ç¼–é˜Ÿæ¨¡å¼ï¼‰- å¢å¼ºç‰ˆé‡è¯•æœºåˆ¶"""
        try:
            if self.video_streaming:
                print("âš  è§†é¢‘æµå·²åœ¨è¿è¡Œä¸­")
                return True
            
            print("ğŸ“¹ å¯åŠ¨Telloè§†é¢‘æµï¼ˆç¼–é˜Ÿæ¨¡å¼ï¼‰...")
            
            # ğŸ”§ æ–°å¢ï¼šè®¾ç½®æ‘„åƒå¤´æ–¹å‘ï¼ˆå¼ºåˆ¶è¦æ±‚ï¼‰
            print("ğŸ“· è®¾ç½®æ‘„åƒå¤´æ–¹å‘...")
            try:
                self.tello.set_video_direction(0)
                print("âœ… æ‘„åƒå¤´æ–¹å‘è®¾ç½®æˆåŠŸ")
                time.sleep(1)  # ç­‰å¾…è®¾ç½®ç”Ÿæ•ˆ
            except Exception as direction_error:
                print(f"âš  æ‘„åƒå¤´æ–¹å‘è®¾ç½®å¤±è´¥: {direction_error}")
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹
            
            # ç¬¬ä¸€æ­¥ï¼šå‘é€streamonå‘½ä»¤
            self.tello.streamon()
            print("âœ… streamonå‘½ä»¤å·²å‘é€")
            
            # ç¬¬äºŒæ­¥ï¼šç­‰å¾…è§†é¢‘æµç¨³å®š
            print("â³ ç­‰å¾…è§†é¢‘æµç¨³å®š...")
            time.sleep(5)  # å¢åŠ ç­‰å¾…æ—¶é—´åˆ°5ç§’
            
            # ç¬¬ä¸‰æ­¥ï¼šå°è¯•è·å–è§†é¢‘å¸§è¯»å–å™¨ï¼ˆå¤šæ¬¡é‡è¯•ï¼‰
            max_retries = 5
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    print(f"ğŸ”„ å°è¯•è·å–è§†é¢‘å¸§è¯»å–å™¨ ({retry_count + 1}/{max_retries})...")
                    
                    # è·å–è§†é¢‘å¸§è¯»å–å™¨
                    self.frame_read = self.tello.get_frame_read()
                    
                    if self.frame_read is None:
                        print("âŒ å¸§è¯»å–å™¨åˆ›å»ºå¤±è´¥")
                        retry_count += 1
                        time.sleep(2)
                        continue
                    
                    # ç¬¬å››æ­¥ï¼šç­‰å¾…ç¬¬ä¸€å¸§å‡†å¤‡å°±ç»ª
                    frame_wait_count = 0
                    max_frame_waits = 15  # æœ€å¤šç­‰å¾…15ç§’
                    
                    print("â³ ç­‰å¾…ç¬¬ä¸€å¸§å‡†å¤‡å°±ç»ª...")
                    while frame_wait_count < max_frame_waits:
                        try:
                            frame = self.frame_read.frame
                            if frame is not None and frame.size > 0:
                                # éªŒè¯å¸§çš„åŸºæœ¬å±æ€§
                                height, width = frame.shape[:2]
                                if height > 0 and width > 0:
                                    print(f"âœ… è·å¾—æœ‰æ•ˆè§†é¢‘å¸§ï¼Œåˆ†è¾¨ç‡: {width}x{height}")
                                    self.video_streaming = True
                                    return True
                                    
                        except Exception as frame_error:
                            print(f"âš  å¸§æ£€æŸ¥å‡ºé”™: {frame_error}")
                        
                        frame_wait_count += 1
                        time.sleep(1)
                        print(f"â³ ç­‰å¾…è§†é¢‘å¸§... ({frame_wait_count}/{max_frame_waits})")
                    
                    print("âŒ ç­‰å¾…è§†é¢‘å¸§è¶…æ—¶")
                    retry_count += 1
                    
                    # æ¸…ç†å¤±è´¥çš„å¸§è¯»å–å™¨
                    self.frame_read = None
                    time.sleep(2)
                    
                except Exception as retry_error:
                    print(f"âŒ ç¬¬{retry_count + 1}æ¬¡é‡è¯•å¤±è´¥: {retry_error}")
                    retry_count += 1
                    self.frame_read = None
                    time.sleep(2)
            
            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
            print("âŒ è§†é¢‘æµå¯åŠ¨å¤±è´¥ï¼šæ— æ³•è·å–æœ‰æ•ˆè§†é¢‘å¸§")
            
            # å°è¯•é‡ç½®è§†é¢‘æµ
            try:
                print("ğŸ”„ å°è¯•é‡ç½®è§†é¢‘æµ...")
                self.tello.streamoff()
                time.sleep(2)
                return False
            except:
                pass
            
            return False
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨è§†é¢‘æµå¼‚å¸¸: {e}")
            self.video_streaming = False
            self.frame_read = None
            return False
    
    def stop_video_stream(self):
        """åœæ­¢è§†é¢‘æµ - å¢å¼ºç‰ˆæ¸…ç†"""
        try:
            if not self.video_streaming:
                return True
            
            print("ğŸ“¹ åœæ­¢Telloè§†é¢‘æµ...")
            
            # æ ‡è®°ä¸ºåœæ­¢çŠ¶æ€
            self.video_streaming = False
            
            # æ¸…ç†å¸§è¯»å–å™¨
            if self.frame_read:
                try:
                    # å°è¯•åœæ­¢å¸§è¯»å–å™¨ï¼ˆå¦‚æœæœ‰stopæ–¹æ³•ï¼‰
                    if hasattr(self.frame_read, 'stop'):
                        self.frame_read.stop()
                except:
                    pass
                finally:
                    self.frame_read = None
            
            # å‘é€streamoffå‘½ä»¤
            self.tello.streamoff()
            
            # ç»™ä¸€ç‚¹æ—¶é—´è®©è§†é¢‘æµå®Œå…¨åœæ­¢
            time.sleep(2)
            
            print("âœ… Telloè§†é¢‘æµå·²åœæ­¢")
            return True
            
        except Exception as e:
            print(f"âŒ åœæ­¢è§†é¢‘æµå¤±è´¥: {e}")
            # å¼ºåˆ¶æ¸…ç†çŠ¶æ€
            self.video_streaming = False
            self.frame_read = None
            return False
    
    def _get_valid_frame(self, max_attempts=10, skip_dark_frames=True):
        """è·å–æœ‰æ•ˆçš„è§†é¢‘å¸§ï¼ˆå¸¦é‡è¯•æœºåˆ¶å’Œé»‘å¸§æ£€æµ‹ï¼‰"""
        if not self.video_streaming or not self.frame_read:
            return None
        
        for attempt in range(max_attempts):
            try:
                frame = self.frame_read.frame
                
                if frame is not None and frame.size > 0:
                    # éªŒè¯å¸§çš„åŸºæœ¬å±æ€§
                    if len(frame.shape) >= 2 and frame.shape[0] > 0 and frame.shape[1] > 0:
                        
                        # ğŸ”§ æ–°å¢ï¼šæ£€æµ‹å¹¶è·³è¿‡çº¯é»‘å¸§æˆ–è¿‡æš—å¸§
                        if skip_dark_frames and self._is_frame_too_dark(frame):
                            print(f"âš« è·³è¿‡è¿‡æš—å¸§ ({attempt + 1}/{max_attempts})...")
                            time.sleep(0.3)  # ç¨ç­‰ç‰‡åˆ»å†è·å–ä¸‹ä¸€å¸§
                            continue
                        
                        # ğŸ”§ æ–°å¢ï¼šåŸºæœ¬å›¾åƒè´¨é‡æ£€æŸ¥
                        if self._is_frame_quality_good(frame):
                            return frame
                        else:
                            print(f"ğŸ“· å¸§è´¨é‡ä¸ä½³ï¼Œé‡è¯• ({attempt + 1}/{max_attempts})...")
                
                print(f"â³ å°è¯•è·å–æœ‰æ•ˆå¸§ ({attempt + 1}/{max_attempts})...")
                time.sleep(0.5)
                
            except Exception as e:
                print(f"âŒ è·å–å¸§æ—¶å‡ºé”™: {e}")
                time.sleep(0.5)
        
        print("âŒ æ— æ³•è·å–æœ‰æ•ˆè§†é¢‘å¸§")
        return None
    
    def _is_frame_too_dark(self, frame, dark_threshold=15):
        """æ£€æµ‹å¸§æ˜¯å¦è¿‡æš—ï¼ˆçº¯é»‘æˆ–æ¥è¿‘é»‘è‰²ï¼‰"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾è®¡ç®—å¹³å‡äº®åº¦
            if len(frame.shape) == 3:
                gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
            else:
                gray = frame
            
            mean_brightness = cv2.mean(gray)[0]
            
            # å¦‚æœå¹³å‡äº®åº¦ä½äºé˜ˆå€¼ï¼Œè®¤ä¸ºæ˜¯æš—å¸§
            if mean_brightness < dark_threshold:
                print(f"ğŸ” æ£€æµ‹åˆ°æš—å¸§ï¼Œå¹³å‡äº®åº¦: {mean_brightness:.1f}")
                return True
            
            return False
            
        except Exception as e:
            print(f"âš  æš—å¸§æ£€æµ‹å‡ºé”™: {e}")
            return False
    
    def _is_frame_quality_good(self, frame, variance_threshold=40):
        """æ£€æµ‹å¸§çš„åŸºæœ¬è´¨é‡"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(frame.shape) == 3:
                gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
            else:
                gray = frame
            
            # è®¡ç®—å›¾åƒæ–¹å·®ï¼ˆåˆ¤æ–­æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç»†èŠ‚ï¼‰
            variance = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            if variance < variance_threshold:
                print(f"ğŸ“· å¸§ç»†èŠ‚ä¸è¶³ï¼Œæ–¹å·®: {variance:.1f}")
                return False
            
            return True
            
        except Exception as e:
            print(f"âš  å¸§è´¨é‡æ£€æµ‹å‡ºé”™: {e}")
            return True  # å‡ºé”™æ—¶å‡è®¾è´¨é‡è‰¯å¥½

    def capture_image(self, filename=None):
        """æ•è·å½“å‰è§†é¢‘å¸§å¹¶ä¿å­˜ä¸ºå›¾ç‰‡ï¼ˆå¢å¼ºç‰ˆé”™è¯¯å¤„ç†ï¼‰"""
        try:
            if not self.video_streaming or not self.frame_read:
                print("âŒ è§†é¢‘æµæœªå¯åŠ¨ï¼Œæ— æ³•æ•è·å›¾ç‰‡")
                return None
            
            print("ğŸ“¸ æ­£åœ¨æ•è·å›¾ç‰‡...")
            
            # ä½¿ç”¨å¢å¼ºçš„å¸§è·å–æ–¹æ³•
            frame = self._get_valid_frame()
            
            if frame is None:
                print("âŒ æ— æ³•è·å–æœ‰æ•ˆè§†é¢‘å¸§")
                return None
            
            # ğŸ”§ ä¿®å¤ï¼šå°†RGBè½¬æ¢ä¸ºBGRæ ¼å¼ï¼ˆTelloé»˜è®¤è¾“å‡ºRGBæ ¼å¼ï¼‰
            try:
                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                print("âœ… è§†é¢‘å¸§é¢œè‰²æ ¼å¼è½¬æ¢æˆåŠŸ")
            except Exception as color_error:
                print(f"âš  é¢œè‰²æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å¸§: {color_error}")
                frame_bgr = frame
            
            # ç”Ÿæˆæ–‡ä»¶å
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"tello_capture_{timestamp}.jpg"
            
            # ç¡®ä¿æ–‡ä»¶åæœ‰æ­£ç¡®çš„æ‰©å±•å
            if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                filename += '.jpg'
            
            # å®Œæ•´æ–‡ä»¶è·¯å¾„
            filepath = os.path.join(self.capture_folder, filename)
            
            # ä¿å­˜å›¾ç‰‡ï¼ˆä½¿ç”¨BGRæ ¼å¼ï¼‰
            success = cv2.imwrite(filepath, frame_bgr)
            
            if success:
                # éªŒè¯æ–‡ä»¶ç¡®å®è¢«ä¿å­˜
                if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
                    print(f"ğŸ“¸ å›¾ç‰‡å·²ä¿å­˜: {filepath}")
                    return filepath
                else:
                    print("âŒ å›¾ç‰‡ä¿å­˜éªŒè¯å¤±è´¥")
                    return None
            else:
                print("âŒ ä¿å­˜å›¾ç‰‡å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âŒ æ•è·å›¾ç‰‡å¼‚å¸¸: {e}")
            return None
    
    def capture_temp_image(self, max_frame_attempts=15):
        """æ•è·ä¸´æ—¶å›¾ç‰‡ï¼ˆç”¨äºè¯†åˆ«ååˆ é™¤ï¼‰- å¢å¼ºç‰ˆé¿å…é»‘å¸§"""
        try:
            if not self.video_streaming or not self.frame_read:
                print("âŒ è§†é¢‘æµæœªå¯åŠ¨ï¼Œæ— æ³•æ•è·ä¸´æ—¶å›¾ç‰‡")
                return None
            
            print("ğŸ“¸ æ­£åœ¨è·å–é«˜è´¨é‡è§†é¢‘å¸§ç”¨äºè¯†åˆ«...")
            
            # ä½¿ç”¨å¢å¼ºçš„å¸§è·å–æ–¹æ³•ï¼ˆæ›´å¤šé‡è¯•æ¬¡æ•°ï¼Œä¸¥æ ¼è´¨é‡æ£€æŸ¥ï¼‰
            frame = self._get_valid_frame(max_attempts=max_frame_attempts, skip_dark_frames=True)
            
            if frame is None:
                print("âŒ æ— æ³•è·å–æœ‰æ•ˆè§†é¢‘å¸§")
                return None
            
            # è¾“å‡ºå¸§çš„åŸºæœ¬ä¿¡æ¯ç”¨äºè°ƒè¯•
            if len(frame.shape) == 3:
                gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
                mean_brightness = cv2.mean(gray)[0]
                print(f"âœ… è·å¾—é«˜è´¨é‡å¸§ï¼Œäº®åº¦: {mean_brightness:.1f}")
            
            # ğŸ”§ ä¿®å¤ï¼šå°†RGBè½¬æ¢ä¸ºBGRæ ¼å¼
            try:
                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            except Exception as color_error:
                print(f"âš  é¢œè‰²æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å¸§: {color_error}")
                frame_bgr = frame
            
            # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            temp_filename = f"temp_recognition_{int(time.time())}.jpg"
            temp_filepath = os.path.join(self.capture_folder, temp_filename)
            
            # ä½¿ç”¨BGRæ ¼å¼ä¿å­˜
            success = cv2.imwrite(temp_filepath, frame_bgr)
            
            if success and os.path.exists(temp_filepath):
                print(f"ğŸ“¸ ä¸´æ—¶å›¾ç‰‡å·²ä¿å­˜: {temp_filepath}")
                return temp_filepath
            else:
                print("âŒ ä¸´æ—¶å›¾ç‰‡ä¿å­˜å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âŒ æ•è·ä¸´æ—¶å›¾ç‰‡å¼‚å¸¸: {e}")
            return None

    def restart_video_stream(self):
        """é‡å¯è§†é¢‘æµ"""
        try:
            print("ğŸ”„ é‡å¯è§†é¢‘æµ...")
            
            # å…ˆåœæ­¢ç°æœ‰è§†é¢‘æµ
            self.stop_video_stream()
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´
            time.sleep(3)
            
            # ğŸ”§ æ–°å¢ï¼šé‡å¯æ—¶ä¹Ÿè®¾ç½®æ‘„åƒå¤´æ–¹å‘
            print("ğŸ“· é‡æ–°è®¾ç½®æ‘„åƒå¤´æ–¹å‘...")
            try:
                self.tello.set_video_direction(0)
                print("âœ… æ‘„åƒå¤´æ–¹å‘é‡æ–°è®¾ç½®æˆåŠŸ")
                time.sleep(0.5)
            except Exception as direction_error:
                print(f"âš  æ‘„åƒå¤´æ–¹å‘é‡æ–°è®¾ç½®å¤±è´¥: {direction_error}")
            
            # é‡æ–°å¯åŠ¨
            success = self.start_video_stream()
            
            if success:
                print("âœ… è§†é¢‘æµé‡å¯æˆåŠŸ")
            else:
                print("âŒ è§†é¢‘æµé‡å¯å¤±è´¥")
            
            return success
            
        except Exception as e:
            print(f"âŒ è§†é¢‘æµé‡å¯å¼‚å¸¸: {e}")
            return False

    def get_stream_status(self):
        """è·å–è§†é¢‘æµè¯¦ç»†çŠ¶æ€"""
        status = {
            'streaming': self.video_streaming,
            'frame_reader_exists': self.frame_read is not None,
            'current_frame_valid': False,
            'frame_shape': None
        }
        
        if self.frame_read:
            try:
                frame = self.frame_read.frame
                if frame is not None and frame.size > 0:
                    status['current_frame_valid'] = True
                    status['frame_shape'] = frame.shape
            except:
                pass
        
        return status

    def recognize_current_view(self, save_image=True, baike_num=0, auto_describe=None):
        """è¯†åˆ«å½“å‰è§†é‡ä¸­çš„ç‰©ä½“ï¼ˆå¸¦å¿ƒè·³ä¿æŒï¼‰"""
        heartbeat_thread = None
        heartbeat_running = False
        
        try:
            # ğŸ”§ æ–°å¢ï¼šå¯åŠ¨è¯†åˆ«æœŸé—´çš„å¿ƒè·³ä¿æŒ
            if hasattr(self, 'tello') and self.tello and hasattr(self.tello, 'send_rc_control'):
                print("ğŸ’“ å¯åŠ¨è¯†åˆ«æœŸé—´å¿ƒè·³ä¿æŒ...")
                heartbeat_running = True
                heartbeat_thread = threading.Thread(
                    target=self._maintain_heartbeat_during_recognition, 
                    args=(lambda: heartbeat_running,), 
                    daemon=True
                )
                heartbeat_thread.start()
            
            # æ•è·å½“å‰å›¾ç‰‡
            print("ğŸ” å¼€å§‹å›¾åƒè¯†åˆ«æµç¨‹...")
            
            if save_image:
                image_path = self.capture_image()
            else:
                # ä½¿ç”¨å¢å¼ºçš„ä¸´æ—¶å›¾ç‰‡æ•è·ï¼ˆé¿å…é»‘å¸§ï¼‰
                image_path = self.capture_temp_image(max_frame_attempts=15)
            
            if not image_path:
                print("âŒ å›¾ç‰‡æ•è·å¤±è´¥")
                return None
            
            print("ğŸ¤– æ­£åœ¨è°ƒç”¨ç™¾åº¦å›¾åƒè¯†åˆ«API...")
            
            # è¯†åˆ«å›¾ç‰‡ - è¿™ä¸ªè¿‡ç¨‹å¯èƒ½è€—æ—¶è¾ƒé•¿
            result = self.baidu_vision.recognize_image_file(image_path, baike_num)
            
            if result:
                self.latest_recognition_result = result
                summary = self.baidu_vision.format_recognition_summary(result)
                print(f"ğŸ” å½“å‰è§†é‡è¯†åˆ«ç»“æœ: {summary}")
                
                # è¯¦ç»†ç»“æœ
                top_objects = self.baidu_vision.get_top_objects(result, 5)
                for i, obj in enumerate(top_objects, 1):
                    category_info = f" ({obj['category']})" if obj['category'] != 'æœªåˆ†ç±»' else ""
                    print(f"   {i}. {obj['name']}: {obj['confidence']:.1f}%{category_info}")
                
                # ç”Ÿæˆæ™ºèƒ½æè¿°å¹¶æ’­æŠ¥
                should_describe = auto_describe if auto_describe is not None else self.auto_description_enabled
                if should_describe:
                    print("ğŸ—£ å¼€å§‹ç”Ÿæˆæ™ºèƒ½æè¿°...")
                    self._generate_and_speak_description(result)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if not save_image and image_path and os.path.exists(image_path):
                    try:
                        os.remove(image_path)
                        print("ğŸ—‘ï¸ ä¸´æ—¶è¯†åˆ«æ–‡ä»¶å·²æ¸…ç†")
                    except:
                        pass
                
                return result
            else:
                print("âŒ å›¾åƒè¯†åˆ«å¤±è´¥")
                if self.auto_description_enabled:
                    self.speech_synthesis.speak("è¯†åˆ«å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
                return None
                
        except Exception as e:
            print(f"âŒ è¯†åˆ«å½“å‰è§†é‡å¼‚å¸¸: {e}")
            return None
        finally:
            # ğŸ”§ åœæ­¢å¿ƒè·³ä¿æŒ
            if heartbeat_thread and heartbeat_running:
                print("ğŸ’“ åœæ­¢è¯†åˆ«æœŸé—´å¿ƒè·³ä¿æŒ")
                heartbeat_running = False
                try:
                    heartbeat_thread.join(timeout=2)
                except:
                    pass
    
    def _maintain_heartbeat_during_recognition(self, should_continue):
        """åœ¨è¯†åˆ«è¿‡ç¨‹ä¸­ç»´æŒå¿ƒè·³ï¼ˆç‹¬ç«‹çº¿ç¨‹ï¼‰"""
        try:
            while should_continue():
                try:
                    # å‘é€æ‚¬åœæŒ‡ä»¤ä¿æŒè¿æ¥
                    if hasattr(self, 'tello') and self.tello:
                        self.tello.send_rc_control(0, 0, 0, 0)
                    
                    time.sleep(1.5)  # æ¯1.5ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
                    
                except Exception as e:
                    print(f"âš  è¯†åˆ«å¿ƒè·³å‘é€å¤±è´¥: {e}")
                    time.sleep(1)
        
        except Exception as e:
            print(f"âŒ è¯†åˆ«å¿ƒè·³çº¿ç¨‹å¼‚å¸¸: {e}")

    def _generate_and_speak_description(self, recognition_result):
        """ç”Ÿæˆæ™ºèƒ½æè¿°å¹¶è¯­éŸ³æ’­æŠ¥"""
        try:
            if not recognition_result or 'objects' not in recognition_result:
                return
            
            print("ğŸ¤– æ­£åœ¨ç”Ÿæˆæ™ºèƒ½æè¿°...")
            
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯æ˜¯å¦æœ‰æè¿°ç”Ÿæˆæ–¹æ³•
            if not hasattr(self.llm_client, 'generate_vision_description'):
                print("âš  LLMå®¢æˆ·ç«¯ç¼ºå°‘å›¾åƒæè¿°åŠŸèƒ½ï¼Œä½¿ç”¨ç®€å•æè¿°")
                fallback_description = self._generate_simple_description(recognition_result)
                print(f"ğŸ“¢ ç®€å•æè¿°: {fallback_description}")
                self.speech_synthesis.speak(fallback_description)
                return
            
            # ä½¿ç”¨LLMç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
            description = self.llm_client.generate_vision_description(recognition_result)
            
            if description and description not in ["æè¿°ç”Ÿæˆå¤±è´¥", "æè¿°ç”Ÿæˆå‡ºé”™", "è¯†åˆ«ç»“æœå¤„ç†å¤±è´¥"]:
                print(f"ğŸ“¢ æ™ºèƒ½æè¿°: {description}")
                # è¯­éŸ³æ’­æŠ¥æè¿°
                self.speech_synthesis.speak(description, priority=True)
            else:
                # å¦‚æœLLMæè¿°å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ ¼å¼
                print("âš  LLMæè¿°ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                fallback_description = self._generate_simple_description(recognition_result)
                print(f"ğŸ“¢ ç®€å•æè¿°: {fallback_description}")
                self.speech_synthesis.speak(fallback_description)
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæè¿°å¼‚å¸¸: {e}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            
            # ä½¿ç”¨ç®€å•æè¿°ä½œä¸ºæœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
            try:
                fallback_description = self._generate_simple_description(recognition_result)
                print(f"ğŸ“¢ å¤‡ç”¨æè¿°: {fallback_description}")
                self.speech_synthesis.speak(fallback_description)
            except Exception as fallback_error:
                print(f"âŒ å¤‡ç”¨æè¿°ä¹Ÿå¤±è´¥: {fallback_error}")
                self.speech_synthesis.speak("è¯†åˆ«å®Œæˆï¼Œä½†æè¿°ç”Ÿæˆå¤±è´¥")
    
    def _generate_simple_description(self, recognition_result):
        """ç”Ÿæˆç®€å•æè¿°ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            top_objects = self.baidu_vision.get_top_objects(recognition_result, 2)
            
            if not top_objects:
                return "æœªè¯†åˆ«åˆ°æ˜ç¡®ç‰©ä½“"
            
            if len(top_objects) == 1:
                obj = top_objects[0]
                return f"æˆ‘çœ‹åˆ°{obj['name']}"
            else:
                obj1, obj2 = top_objects[0], top_objects[1]
                return f"æˆ‘çœ‹åˆ°{obj1['name']}å’Œ{obj2['name']}"
                
        except Exception as e:
            return "è¯†åˆ«ç»“æœå¤„ç†ä¸­"
    
    def start_auto_recognition(self, interval=5.0):
        """å¯åŠ¨è‡ªåŠ¨è¯†åˆ«æ¨¡å¼"""
        if self.recognition_running:
            print("âš  è‡ªåŠ¨è¯†åˆ«å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.auto_recognition = True
        self.recognition_interval = max(3.0, interval)  # æœ€å°é—´éš”3ç§’
        self.recognition_running = True
        
        self.recognition_thread = threading.Thread(target=self._auto_recognition_worker, daemon=True)
        self.recognition_thread.start()
        
        print(f"ğŸ” è‡ªåŠ¨è¯†åˆ«å·²å¯åŠ¨ï¼Œé—´éš”: {self.recognition_interval}ç§’")
    
    def stop_auto_recognition(self):
        """åœæ­¢è‡ªåŠ¨è¯†åˆ«æ¨¡å¼"""
        if not self.recognition_running:
            return
        
        print("ğŸ” åœæ­¢è‡ªåŠ¨è¯†åˆ«...")
        self.auto_recognition = False
        self.recognition_running = False
        
        if self.recognition_thread:
            self.recognition_thread.join(timeout=3)
        
        print("âœ… è‡ªåŠ¨è¯†åˆ«å·²åœæ­¢")
    
    def _auto_recognition_worker(self):
        """è‡ªåŠ¨è¯†åˆ«å·¥ä½œçº¿ç¨‹ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        consecutive_failures = 0
        max_failures = 3  # è¿ç»­å¤±è´¥3æ¬¡åæš‚åœ
        
        while self.recognition_running and self.auto_recognition:
            try:
                current_time = time.time()
                
                # æ£€æŸ¥æ˜¯å¦åˆ°äº†è¯†åˆ«æ—¶é—´
                if current_time - self.last_recognition_time >= self.recognition_interval:
                    self.last_recognition_time = current_time
                    
                    print("ğŸ” è‡ªåŠ¨è¯†åˆ«å¼€å§‹...")
                    
                    # æ‰§è¡Œè¯†åˆ«ï¼ˆä¸ä¿å­˜å›¾ç‰‡ï¼Œå¯ç”¨æè¿°ï¼Œå¸¦å¿ƒè·³ä¿æŒï¼‰
                    result = self.recognize_current_view(save_image=False, auto_describe=True)
                    
                    if result:
                        consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
                        print("âœ… è‡ªåŠ¨è¯†åˆ«æˆåŠŸ")
                    else:
                        consecutive_failures += 1
                        print(f"âŒ è‡ªåŠ¨è¯†åˆ«å¤±è´¥ ({consecutive_failures}/{max_failures})")
                        
                        # è¿ç»­å¤±è´¥è¿‡å¤šï¼Œæš‚åœè‡ªåŠ¨è¯†åˆ«
                        if consecutive_failures >= max_failures:
                            print("âš  è¿ç»­è¯†åˆ«å¤±è´¥è¿‡å¤šï¼Œæš‚åœè‡ªåŠ¨è¯†åˆ«")
                            self.auto_recognition = False
                            self.speech_synthesis.speak("è§†è§‰è¯†åˆ«å‡ºç°é—®é¢˜ï¼Œå·²æš‚åœè‡ªåŠ¨è¯†åˆ«")
                            break
                
                time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                print(f"âŒ è‡ªåŠ¨è¯†åˆ«çº¿ç¨‹é”™è¯¯: {e}")
                consecutive_failures += 1
                time.sleep(2)
                
                if consecutive_failures >= max_failures:
                    print("âš  è‡ªåŠ¨è¯†åˆ«çº¿ç¨‹é”™è¯¯è¿‡å¤šï¼Œåœæ­¢è‡ªåŠ¨è¯†åˆ«")
                    self.auto_recognition = False
                    break
    
    def toggle_auto_description(self):
        """åˆ‡æ¢è‡ªåŠ¨æè¿°åŠŸèƒ½"""
        self.auto_description_enabled = not self.auto_description_enabled
        status = "å¼€å¯" if self.auto_description_enabled else "å…³é—­"
        print(f"ğŸ“¢ è‡ªåŠ¨æè¿°æ’­æŠ¥å·²{status}")
        self.speech_synthesis.speak(f"è‡ªåŠ¨æè¿°æ’­æŠ¥å·²{status}")
        return self.auto_description_enabled
    
    def speak_recognition_result(self):
        """æ’­æŠ¥æœ€æ–°è¯†åˆ«ç»“æœ"""
        if self.latest_recognition_result:
            self._generate_and_speak_description(self.latest_recognition_result)
        else:
            self.speech_synthesis.speak("æš‚æ— è¯†åˆ«ç»“æœ")
    
    def test_speech_synthesis(self):
        """æµ‹è¯•è¯­éŸ³åˆæˆ"""
        return self.speech_synthesis.test_speech()
    
    def get_latest_recognition(self):
        """è·å–æœ€æ–°çš„è¯†åˆ«ç»“æœ"""
        return self.latest_recognition_result
    
    def display_video_stream(self, window_name="Tello Camera"):
        """æ˜¾ç¤ºè§†é¢‘æµï¼ˆç”¨äºè°ƒè¯•ï¼Œé€‚é…ç¼–é˜Ÿæ¨¡å¼ï¼‰"""
        try:
            if not self.video_streaming or not self.frame_read:
                print("âŒ è§†é¢‘æµæœªå¯åŠ¨")
                return
            
            print(f"ğŸ“º æ˜¾ç¤ºè§†é¢‘æµçª—å£: {window_name}")
            print("ğŸ’¡ æŒ‰ 'q' é”®é€€å‡ºæ˜¾ç¤ºï¼ŒæŒ‰ 'c' é”®æ•è·å›¾ç‰‡ï¼ŒæŒ‰ 'r' é”®è¯†åˆ«å½“å‰ç”»é¢")
            
            # è®¾ç½®çª—å£
            cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)
            
            # è®°å½•å¸§ç‡
            frame_count = 0
            start_time = time.time()
            
            while True:
                frame = self.frame_read.frame
                
                if frame is not None and frame.size > 0:
                    # ğŸ”§ ä¿®å¤ï¼šå°†RGBè½¬æ¢ä¸ºBGRæ ¼å¼ç”¨äºæ˜¾ç¤º
                    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    
                    # æ·»åŠ è¯†åˆ«ç»“æœå åŠ æ˜¾ç¤º
                    display_frame = self._add_recognition_overlay(frame_bgr)
                    
                    # æ·»åŠ å¸§ç‡ä¿¡æ¯
                    frame_count += 1
                    current_time = time.time()
                    if current_time - start_time >= 5.0:  # æ¯5ç§’è®¡ç®—ä¸€æ¬¡å¸§ç‡
                        fps = frame_count / (current_time - start_time)
                        frame_count = 0
                        start_time = current_time
                        
                        # åœ¨å›¾åƒä¸Šæ˜¾ç¤ºå¸§ç‡
                        cv2.putText(display_frame, f"FPS: {fps:.1f}", (10, display_frame.shape[0] - 10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    
                    # æ·»åŠ é¢œè‰²æ ¼å¼æ ‡è¯†
                    cv2.putText(display_frame, "BGR Format", (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                    cv2.imshow(window_name, display_frame)
                else:
                    print("âš  è·å–åˆ°æ— æ•ˆè§†é¢‘å¸§")
                
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q') or key == 27:  # 'q' æˆ– ESC é”®
                    break
                elif key == ord('c'):
                    self.capture_image()
                elif key == ord('r'):
                    self.recognize_current_view()
            
            cv2.destroyWindow(window_name)
            print("ğŸ“º è§†é¢‘æ˜¾ç¤ºçª—å£å·²å…³é—­")
            
        except Exception as e:
            print(f"âŒ æ˜¾ç¤ºè§†é¢‘æµå¼‚å¸¸: {e}")
            try:
                cv2.destroyAllWindows()
            except:
                pass
    
    def _add_recognition_overlay(self, frame):
        """åœ¨è§†é¢‘å¸§ä¸Šå åŠ è¯†åˆ«ç»“æœ"""
        try:
            if self.latest_recognition_result:
                overlay_frame = frame.copy()
                
                # è·å–å‰3ä¸ªè¯†åˆ«ç»“æœ
                top_objects = self.baidu_vision.get_top_objects(self.latest_recognition_result, 3)
                
                # åœ¨å·¦ä¸Šè§’æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                y_offset = 30
                for obj in top_objects:
                    text = f"{obj['name']}: {obj['confidence']:.1f}%"
                    cv2.putText(overlay_frame, text, (10, y_offset), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    y_offset += 30
                
                return overlay_frame
            else:
                return frame
                
        except Exception as e:
            return frame
    
    def get_vision_status(self):
        """è·å–è§†è§‰æ¨¡å—çŠ¶æ€"""
        status_parts = []
        
        if self.video_streaming:
            status_parts.append("è§†é¢‘æµ: å¼€å¯")
        else:
            status_parts.append("è§†é¢‘æµ: å…³é—­")
        
        if self.auto_recognition:
            status_parts.append(f"è‡ªåŠ¨è¯†åˆ«: å¼€å¯({self.recognition_interval}s)")
        else:
            status_parts.append("è‡ªåŠ¨è¯†åˆ«: å…³é—­")
        
        # æ·»åŠ è¯­éŸ³æè¿°çŠ¶æ€
        if self.auto_description_enabled:
            status_parts.append("æ™ºèƒ½æè¿°: å¼€å¯")
        else:
            status_parts.append("æ™ºèƒ½æè¿°: å…³é—­")
        
        # æ·»åŠ è¯­éŸ³é˜Ÿåˆ—çŠ¶æ€
        queue_size = self.speech_synthesis.get_queue_size()
        if queue_size > 0:
            status_parts.append(f"è¯­éŸ³é˜Ÿåˆ—: {queue_size}æ¡")
        
        if self.latest_recognition_result:
            summary = self.baidu_vision.format_recognition_summary(self.latest_recognition_result)
            status_parts.append(f"æœ€æ–°è¯†åˆ«: {summary}")
        
        return " | ".join(status_parts)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # åœæ­¢è‡ªåŠ¨è¯†åˆ«
            self.stop_auto_recognition()
            
            # åœæ­¢è§†é¢‘æµ
            self.stop_video_stream()
            
            # å…³é—­è¯­éŸ³åˆæˆ
            self.speech_synthesis.shutdown()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files()
            
            print("âœ… è§†è§‰æ¨¡å—å·²æ¸…ç†")
            
        except Exception as e:
            print(f"âš  è§†è§‰æ¨¡å—æ¸…ç†æ—¶å‡ºé”™: {e}")
    
    def _cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            temp_files = [f for f in os.listdir(self.capture_folder) 
                         if f.startswith('temp_recognition_')]
            
            for temp_file in temp_files:
                temp_path = os.path.join(self.capture_folder, temp_file)
                try:
                    os.remove(temp_path)
                except:
                    pass
                    
        except Exception as e:
            pass
