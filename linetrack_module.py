"""
ç²¾ç®€å·¡çº¿æ¨¡å— - ç”¨äºæ— äººæœºè½¨è¿¹è·Ÿéš
åŸºäºä¸‹è§†æ‘„åƒå¤´çš„è½¨è¿¹æ£€æµ‹å’Œè·Ÿéšæ§åˆ¶
é‡‡ç”¨ linetrack3.py çš„ä¼˜åŒ–æ£€æµ‹æµç¨‹
"""
import cv2
import time
import numpy as np
import threading
import queue
from collections import deque
import traceback

# ==================== æš—è§’æ ¡æ­£ç±» ====================
class VignetteCorrector:
    """æ— äººæœºé•œå¤´æš—è§’æ ¡æ­£å™¨"""
    
    def __init__(self, image_shape, vignette_strength=0.4):
        self.height, self.width = image_shape[:2]
        self.vignette_strength = vignette_strength
        self.correction_mask = self._create_correction_mask()
        print(f"æš—è§’æ ¡æ­£å™¨åˆå§‹åŒ–: {self.width}x{self.height}, å¼ºåº¦={vignette_strength}")
    
    def _create_correction_mask(self):
        center_x, center_y = self.width // 2, self.height // 2
        y, x = np.ogrid[:self.height, :self.width]
        distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)
        max_distance = np.sqrt(center_x**2 + center_y**2)
        normalized_distance = distance / max_distance
        correction_mask = 1 + self.vignette_strength * (normalized_distance ** 2)
        correction_mask = np.clip(correction_mask, 1.0, 2.0)
        return correction_mask.astype(np.float32)
    
    def correct_vignette(self, image):
        if image is None:
            return None
            
        current_height, current_width = image.shape[:2]
        if current_height != self.height or current_width != self.width:
            self.height, self.width = current_height, current_width
            self.correction_mask = self._create_correction_mask()
            
        image_float = image.astype(np.float32)
        
        if len(image.shape) == 3:
            corrected = np.zeros_like(image_float)
            for i in range(image.shape[2]):
                corrected[:,:,i] = image_float[:,:,i] * self.correction_mask
        else:
            corrected = image_float * self.correction_mask
        
        corrected = np.clip(corrected, 0, 255)
        return corrected.astype(np.uint8)

# ==================== è½¨è¿¹é¢„æµ‹å™¨ ====================
class TrajectoryPredictor:
    """è½¨è¿¹é¢„æµ‹å™¨ï¼Œç”¨äºé¢„æµ‹æ€§æ§åˆ¶"""
    
    def __init__(self, history_length=5):
        self.position_history = deque(maxlen=history_length)
        self.direction_history = deque(maxlen=history_length)
        self.time_history = deque(maxlen=history_length)
    
    def add_observation(self, center_pos, direction_angle):
        """æ·»åŠ è§‚æµ‹æ•°æ®"""
        current_time = time.time()
        self.position_history.append(center_pos)
        self.direction_history.append(direction_angle)
        self.time_history.append(current_time)
    
    def predict_next_position(self, steps_ahead=3):
        """é¢„æµ‹ä¸‹ä¸€ä¸ªä½ç½®"""
        if len(self.position_history) < 3:
            return None
        
        # ç®€å•çš„çº¿æ€§é¢„æµ‹
        recent_positions = list(self.position_history)[-3:]
        
        # è®¡ç®—è¿åŠ¨å‘é‡
        dx = recent_positions[-1][0] - recent_positions[-2][0]
        dy = recent_positions[-1][1] - recent_positions[-2][1]
        
        # é¢„æµ‹ä½ç½®
        predicted_x = recent_positions[-1][0] + dx * steps_ahead
        predicted_y = recent_positions[-1][1] + dy * steps_ahead
        
        return (int(predicted_x), int(predicted_y))
    
    def get_movement_trend(self):
        """è·å–è¿åŠ¨è¶‹åŠ¿"""
        if len(self.position_history) < 2:
            return "stable"
        
        recent_positions = list(self.position_history)[-2:]
        dx = recent_positions[-1][0] - recent_positions[-2][0]
        dy = recent_positions[-1][1] - recent_positions[-2][1]
        
        if abs(dx) < 2 and abs(dy) < 2:
            return "stable"
        elif abs(dx) > abs(dy):
            return "horizontal" if dx > 0 else "horizontal_back"
        else:
            return "vertical_down" if dy > 0 else "vertical_up"

class DownwardCoordinateSystem:
    """ä¸‹è§†å›¾åƒåæ ‡ç³»è½¬æ¢å’Œæ§åˆ¶æ˜ å°„ - ä¸linetrack3.pyä¸€è‡´"""
    
    def __init__(self, image_width=320, image_height=240):
        self.width = image_width
        self.height = image_height
        self.center_x = image_width // 2
        self.center_y = image_height // 2
        
        # æ§åˆ¶å‚æ•° - ä¸linetrack3.pyä¿æŒä¸€è‡´
        self.lateral_deadzone = 8        # å·¦å³æ§åˆ¶æ­»åŒº
        self.forward_deadzone = 5        # å‰åæ§åˆ¶æ­»åŒº
        self.position_sensitivity = 0.4   # ä½ç½®æ§åˆ¶æ•æ„Ÿåº¦
        self.direction_sensitivity = 0.8  # æ–¹å‘æ§åˆ¶æ•æ„Ÿåº¦
        self.max_forward_speed = 18      # æœ€å¤§å‰è¿›é€Ÿåº¦
        self.max_lateral_speed = 15      # æœ€å¤§ä¾§å‘é€Ÿåº¦
        self.max_yaw_speed = 20          # æœ€å¤§åèˆªé€Ÿåº¦
        self.yaw_response_factor = 0.7   # åèˆªå“åº”ç³»æ•°
        
        print(f"ä¸‹è§†åæ ‡ç³»åˆå§‹åŒ–: {self.width}x{self.height}, ä¸­å¿ƒ=({self.center_x}, {self.center_y})")
        print("åæ ‡ç³»æ˜ å°„: å·¦=å‰è¿›, å³=åé€€, ä¸Š=å³ä¾§, ä¸‹=å·¦ä¾§")
    
    def image_to_drone_control(self, image_x, image_y):
        """å°†å›¾åƒåæ ‡è½¬æ¢ä¸ºæ— äººæœºæ§åˆ¶æŒ‡ä»¤ - ä¸linetrack3.pyä¸€è‡´"""
        # è®¡ç®—ç›¸å¯¹äºå›¾åƒä¸­å¿ƒçš„åç§»
        offset_x = image_x - self.center_x  # æ­£å€¼=å³åï¼Œè´Ÿå€¼=å·¦å
        offset_y = image_y - self.center_y  # æ­£å€¼=ä¸‹åï¼Œè´Ÿå€¼=ä¸Šå
        
        # åæ ‡è½¬æ¢é€»è¾‘ï¼š
        # å›¾åƒXè½´ï¼ˆå·¦å³ï¼‰-> æ— äººæœºå‰åæ§åˆ¶ (FB)
        # å›¾åƒYè½´ï¼ˆä¸Šä¸‹ï¼‰-> æ— äººæœºå·¦å³æ§åˆ¶ (LR)
        
        # FBæ§åˆ¶ï¼šå›¾åƒå·¦åï¼ˆè´ŸXï¼‰= å‰è¿›ï¼Œå›¾åƒå³åï¼ˆæ­£Xï¼‰= åé€€
        fb_control = -offset_x * self.position_sensitivity
        
        # LRæ§åˆ¶ï¼šå›¾åƒä¸Šåï¼ˆè´ŸYï¼‰= å³ç§»ï¼Œå›¾åƒä¸‹åï¼ˆæ­£Yï¼‰= å·¦ç§»  
        lr_control = -offset_y * self.position_sensitivity
        
        # åº”ç”¨æ­»åŒº
        if abs(fb_control) < self.forward_deadzone:
            fb_control = 0
        if abs(lr_control) < self.lateral_deadzone:
            lr_control = 0
        
        # é™åˆ¶æ§åˆ¶èŒƒå›´
        fb_control = np.clip(fb_control, -self.max_forward_speed, self.max_forward_speed)
        lr_control = np.clip(lr_control, -self.max_lateral_speed, self.max_lateral_speed)
        
        explanation = f"å›¾åƒåç§»({offset_x:.1f},{offset_y:.1f}) -> æ§åˆ¶(FB:{fb_control:.1f}, LR:{lr_control:.1f})"
        
        return {
            'lr': int(lr_control),
            'fb': int(fb_control),
            'offset_x': offset_x,
            'offset_y': offset_y,
            'explanation': explanation
        }
    
    def calculate_direction_control(self, line_angle, target_angle=0):
        """è®¡ç®—æ–¹å‘æ§åˆ¶ - ä¸linetrack3.pyä¸€è‡´"""
        # è§’åº¦åå·®è®¡ç®—
        angle_error = line_angle - target_angle
        
        # å½’ä¸€åŒ–åˆ°[-180, 180]
        while angle_error > 180:
            angle_error -= 360
        while angle_error < -180:
            angle_error += 360
        
        # è®¡ç®—åèˆªæ§åˆ¶
        yaw_control = angle_error * self.direction_sensitivity * self.yaw_response_factor
        yaw_control = np.clip(yaw_control, -self.max_yaw_speed, self.max_yaw_speed)
        
        return int(yaw_control), angle_error

# ==================== æ–¹å‘ä¼˜åŒ–å‡½æ•° ====================
def normalize_angle_to_forward_reference(angle):
    """å°†è§’åº¦å½’ä¸€åŒ–ä¸ºä»¥å‰è¿›æ–¹å‘ä¸ºå‚è€ƒçš„è§’åº¦"""
    normalized = angle
    if normalized > 180:
        normalized -= 360
    return normalized

def calculate_direction_score(normalized_angle):
    """è®¡ç®—æ–¹å‘è¯„åˆ†ï¼Œå‰è¿›æ–¹å‘(0åº¦)å¾—åˆ†æœ€é«˜"""
    angle_diff = abs(normalized_angle)
    if angle_diff > 180:
        angle_diff = 360 - angle_diff
    
    # å‰å‘æ–¹å‘å¾—åˆ†æœ€é«˜
    direction_tolerance = 35
    forward_direction_bias = 2.5
    
    if angle_diff <= direction_tolerance:
        return forward_direction_bias
    elif angle_diff <= 90:
        return 1.0 - (angle_diff / 90.0)
    else:
        return 0

def detect_turn_improved(contour, points):
    """æ”¹è¿›çš„è½¬å¼¯æ£€æµ‹ç®—æ³•"""
    # è®¡ç®—è½®å»“å¤æ‚åº¦
    perimeter = cv2.arcLength(contour, True)
    approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)
    
    # è®¡ç®—å‡¸åŒ…å’Œå‡¸ç¼ºé™·
    hull = cv2.convexHull(contour)
    hull_area = cv2.contourArea(hull)
    contour_area = cv2.contourArea(contour)
    
    # è®¡ç®—å¡«å……åº¦
    solidity = contour_area / hull_area if hull_area > 0 else 0
    
    # è®¡ç®—è½®å»“çš„ä¸»è¦æ–¹å‘å˜åŒ–
    if len(points) >= 10:
        # é‡‡æ ·ç‚¹è¿›è¡Œæ–¹å‘åˆ†æ
        step = max(1, len(points) // 10)
        sampled_points = points[::step]
        
        if len(sampled_points) >= 3:
            directions = []
            for i in range(1, len(sampled_points) - 1):
                prev_pt = sampled_points[i-1]
                curr_pt = sampled_points[i]
                next_pt = sampled_points[i+1]
                
                vec1 = curr_pt - prev_pt
                vec2 = next_pt - curr_pt
                
                if np.linalg.norm(vec1) > 0 and np.linalg.norm(vec2) > 0:
                    # è®¡ç®—ä¸¤å‘é‡å¤¹è§’
                    cos_angle = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
                    cos_angle = np.clip(cos_angle, -1.0, 1.0)
                    angle = np.degrees(np.arccos(cos_angle))
                    directions.append(angle)
            
            # å¦‚æœæœ‰æ˜¾è‘—çš„æ–¹å‘å˜åŒ–ï¼Œè®¤ä¸ºæœ‰è½¬å¼¯
            if directions and (np.max(directions) > 45 or np.std(directions) > 15):
                return True
    
    # åŸºäºå‡ ä½•ç‰¹å¾çš„è½¬å¼¯æ£€æµ‹
    has_turn = (len(approx) > 5) or (solidity < 0.8)
    
    return has_turn

class LineTrackModule:
    """ç²¾ç®€å·¡çº¿æ¨¡å— - é‡‡ç”¨linetrack3.pyä¼˜åŒ–æµç¨‹"""
    
    def __init__(self, tello_controller):
        self.tello_controller = tello_controller
        self.single_tello = tello_controller.single_tello
        
        # çº¿ç¨‹æ§åˆ¶
        self.tracking_thread = None
        self.is_tracking = False
        self.track_lock = threading.Lock()
        
        # è§†é¢‘æµç›¸å…³
        self.frame_read = None
        self.current_frame = None
        self.frame_queue = queue.Queue(maxsize=5)
        
        # å›¾åƒå°ºå¯¸é…ç½®
        self.expected_width = 320
        self.expected_height = 240
        
        # æ§åˆ¶ç³»ç»Ÿ - ä½¿ç”¨å¢å¼ºç‰ˆæœ¬
        self.coord_system = DownwardCoordinateSystem(self.expected_width, self.expected_height)
        self.predictor = TrajectoryPredictor(history_length=5)
        
        # æš—è§’æ ¡æ­£å™¨
        self.vignette_corrector = None
        self.enable_vignette_correction = True
        
        # è£å‰ªè¾¹ç¼˜å‚æ•°
        self.crop_margin = 20
        
        # æ§åˆ¶å‚æ•°
        self.track_alignment_tolerance = 3.0
        self.direction_threshold = 12.0
        self.min_forward_speed = 6
        
        # å·¡çº¿çŠ¶æ€
        self.track_detected = False
        self.last_track_time = 0
        self.control_mode = "SEARCHING"
        self.alignment_score = 0
        
        print("âœ“ å·¡çº¿æ¨¡å—åˆå§‹åŒ–å®Œæˆï¼ˆé‡‡ç”¨linetrack3ä¼˜åŒ–æµç¨‹ï¼‰")
    
    def validate_and_crop_frame(self, frame):
        """éªŒè¯å¹¶è£åˆ‡å›¾åƒåˆ°æ ‡å‡†å°ºå¯¸"""
        if frame is None:
            return None
        
        try:
            current_height, current_width = frame.shape[:2]
            
            # æ£€æŸ¥å›¾åƒå°ºå¯¸æ˜¯å¦å¼‚å¸¸
            if current_width != self.expected_width or current_height != self.expected_height:
                print(f"âš  æ£€æµ‹åˆ°å¼‚å¸¸å›¾åƒå°ºå¯¸: {current_width}x{current_height}ï¼Œæ­£åœ¨è£åˆ‡ä¸º {self.expected_width}x{self.expected_height}")
                
                # å¦‚æœå®½åº¦ä¸åŒ¹é…ï¼Œä»ä¸­å¿ƒè£åˆ‡
                if current_width != self.expected_width:
                    if current_width > self.expected_width:
                        # ä»ä¸­å¿ƒè£åˆ‡å®½åº¦
                        start_x = (current_width - self.expected_width) // 2
                        frame = frame[:, start_x:start_x + self.expected_width]
                    else:
                        # å®½åº¦ä¸è¶³ï¼Œå¡«å……é»‘è‰²è¾¹ç¼˜
                        pad_x = (self.expected_width - current_width) // 2
                        frame = cv2.copyMakeBorder(frame, 0, 0, pad_x, self.expected_width - current_width - pad_x, 
                                                 cv2.BORDER_CONSTANT, value=(0, 0, 0))
                
                # æ›´æ–°å½“å‰å°ºå¯¸
                current_height, current_width = frame.shape[:2]
                
                # å¦‚æœé«˜åº¦å¼‚å¸¸ï¼ˆç‰¹åˆ«æ˜¯ä¸‹æ–¹å¤šå‡ºç»¿è‰²åƒç´ çš„æƒ…å†µï¼‰ï¼Œä»é¡¶éƒ¨è£åˆ‡
                if current_height != self.expected_height:
                    if current_height > self.expected_height:
                        # ä»é¡¶éƒ¨è£åˆ‡åˆ°æ ‡å‡†é«˜åº¦ï¼ˆé¿å…åº•éƒ¨ç»¿è‰²åƒç´ å¹²æ‰°ï¼‰
                        frame = frame[:self.expected_height, :]
                        print(f"âœ“ å·²ä»é¡¶éƒ¨è£åˆ‡å›¾åƒï¼Œç§»é™¤åº•éƒ¨ {current_height - self.expected_height} è¡Œå¼‚å¸¸åƒç´ ")
                    else:
                        # é«˜åº¦ä¸è¶³ï¼Œå¡«å……é»‘è‰²è¾¹ç¼˜
                        pad_y = (self.expected_height - current_height) // 2
                        frame = cv2.copyMakeBorder(frame, pad_y, self.expected_height - current_height - pad_y, 0, 0,
                                                 cv2.BORDER_CONSTANT, value=(0, 0, 0))
                
                # æœ€ç»ˆç¡®ä¿å°ºå¯¸æ­£ç¡®
                final_height, final_width = frame.shape[:2]
                if final_width != self.expected_width or final_height != self.expected_height:
                    frame = cv2.resize(frame, (self.expected_width, self.expected_height))
                    print(f"âœ“ å¼ºåˆ¶è°ƒæ•´å›¾åƒå°ºå¯¸ä¸º {self.expected_width}x{self.expected_height}")
            
            return frame
            
        except Exception as e:
            print(f"âŒ å›¾åƒè£åˆ‡å¤„ç†å¤±è´¥: {e}")
            return None
    
    def detect_track_optimized(self, frame):
        """
        ä¼˜åŒ–çš„è½¨è¿¹æ£€æµ‹å‡½æ•° - é‡‡ç”¨linetrack3.pyçš„æ£€æµ‹æµç¨‹
        """
        if frame is None:
            return {"found": False, "reason": "no_frame"}
        
        # é¦–å…ˆéªŒè¯å’Œè£åˆ‡å›¾åƒ
        validated_frame = self.validate_and_crop_frame(frame)
        if validated_frame is None:
            return {"found": False, "reason": "frame_validation_failed"}
        
        try:
            # æ­¥éª¤1: æš—è§’æ ¡æ­£
            if self.vignette_corrector is not None and self.enable_vignette_correction:
                corrected_frame = self.vignette_corrector.correct_vignette(validated_frame)
            else:
                corrected_frame = validated_frame
            
            # æ­¥éª¤2ï¼šè£å‰ªè¾¹ç¼˜ï¼Œå»é™¤æš—è§’æˆ–è¯¯å·®åŒºåŸŸ
            height, width = corrected_frame.shape[:2]
            if height > self.crop_margin * 2 and width > self.crop_margin * 2:
                cropped_frame = corrected_frame[self.crop_margin:height-self.crop_margin, 
                                              self.crop_margin:width-self.crop_margin]
            else:
                cropped_frame = corrected_frame
            
            # æ­¥éª¤3: è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2GRAY)
            
            # æ­¥éª¤4: é«˜æ–¯æ¨¡ç³Š
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # æ­¥éª¤5: ä½¿ç”¨å›ºå®šé˜ˆå€¼æ–¹æ³•
            _, binary = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY_INV)
            
            # æ£€æŸ¥äºŒå€¼åŒ–ç»“æœ
            white_pixels = np.sum(binary == 255)
            total_pixels = binary.shape[0] * binary.shape[1]
            white_ratio = white_pixels / total_pixels
            
            if white_ratio < 0.001:
                return {"found": False, "reason": "no_white_pixels", "binary": binary, "validated_frame": validated_frame}
            
            # æ­¥éª¤6: ä¼˜åŒ–çš„å½¢æ€å­¦å¤„ç†
            kernel_small = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
            kernel_medium = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            
            # è½»å¾®çš„å¼€è¿ç®—å»é™¤å°å™ªå£°
            binary_cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_small, iterations=1)
            # è½»å¾®çš„é—­è¿ç®—è¿æ¥æ–­è£‚
            binary_cleaned = cv2.morphologyEx(binary_cleaned, cv2.MORPH_CLOSE, kernel_medium, iterations=1)
            
            # æ£€æŸ¥å½¢æ€å­¦å¤„ç†åçš„ç»“æœ
            white_pixels_after = np.sum(binary_cleaned == 255)
            white_ratio_after = white_pixels_after / total_pixels
            
            if white_ratio_after < 0.0005:
                binary_cleaned = binary
            
            # æ­¥éª¤7: è½®å»“æ£€æµ‹
            contours, _ = cv2.findContours(binary_cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return {"found": False, "reason": "no_contours", "binary": binary_cleaned, "validated_frame": validated_frame}
            
            # æ­¥éª¤8: æ”¹è¿›çš„è½¨è¿¹å€™é€‰ç­›é€‰ - åŠ å…¥æ–¹å‘ä¼˜å…ˆçº§
            valid_tracks = []
            
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                
                # é¢ç§¯ç­›é€‰
                if area < 30 or area > 2500:
                    continue
                
                # æ£€æŸ¥è½®å»“æ˜¯å¦ä¸»è¦ç”±ç™½è‰²åƒç´ ç»„æˆ
                mask = np.zeros(binary_cleaned.shape, dtype=np.uint8)
                cv2.fillPoly(mask, [contour], 255)
                white_in_contour = np.sum((binary_cleaned == 255) & (mask == 255))
                contour_area_pixels = np.sum(mask == 255)
                
                if contour_area_pixels > 0:
                    white_ratio_in_contour = white_in_contour / contour_area_pixels
                    
                    # ä¸»è¦ç”±ç™½è‰²åƒç´ ç»„æˆçš„åŒºåŸŸ
                    if white_ratio_in_contour > 0.5:
                        # è®¡ç®—å‡ ä½•ç‰¹å¾
                        rect = cv2.minAreaRect(contour)
                        width_rect, height_rect = rect[1]
                        
                        if width_rect > 0 and height_rect > 0:
                            aspect_ratio = max(width_rect, height_rect) / min(width_rect, height_rect)
                            
                            # è®¡ç®—è½¨è¿¹æ–¹å‘
                            points = contour.reshape(-1, 2)
                            if len(points) >= 5:
                                try:
                                    # ä½¿ç”¨PCAè®¡ç®—ä¸»æ–¹å‘
                                    centroid = np.mean(points, axis=0)
                                    centered_points = points - centroid
                                    cov_matrix = np.cov(centered_points.T)
                                    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)
                                    main_direction = eigenvectors[:, np.argmax(eigenvalues)]
                                    track_angle = np.degrees(np.arctan2(main_direction[1], main_direction[0]))
                                except:
                                    track_angle = rect[2]
                                    if rect[1][0] < rect[1][1]:
                                        track_angle += 90
                            else:
                                track_angle = rect[2]
                                if rect[1][0] < rect[1][1]:
                                    track_angle += 90
                            
                            # å½’ä¸€åŒ–è§’åº¦
                            track_angle = track_angle % 360
                            normalized_angle = normalize_angle_to_forward_reference(track_angle)
                            direction_score = calculate_direction_score(normalized_angle)
                            
                            # è®¡ç®—å¡«å……åº¦
                            hull = cv2.convexHull(contour)
                            hull_area = cv2.contourArea(hull)
                            solidity = area / hull_area if hull_area > 0 else 0
                            
                            # æ”¹è¿›çš„è¯„åˆ†ç³»ç»Ÿ
                            score = 0
                            
                            # é•¿å®½æ¯”è¯„åˆ†
                            if aspect_ratio >= 1.5:
                                score += 2
                                if aspect_ratio >= 3.0:
                                    score += 1
                            
                            # é¢ç§¯è¯„åˆ†
                            if 50 <= area <= 5000:
                                score += 2
                            elif area > 5000:
                                score += 1
                            
                            # å¡«å……åº¦è¯„åˆ†
                            if solidity > 0.6:
                                score += 1
                            
                            # æ–¹å‘è¯„åˆ†
                            score += direction_score
                            
                            if score >= 2:
                                valid_tracks.append({
                                    'contour': contour,
                                    'area': area,
                                    'aspect_ratio': aspect_ratio,
                                    'solidity': solidity,
                                    'track_angle': track_angle,
                                    'normalized_angle': normalized_angle,
                                    'direction_score': direction_score,
                                    'score': score,
                                    'rect': rect,
                                    'width': width_rect,
                                    'height': height_rect
                                })
            
            if not valid_tracks:
                return {"found": False, "reason": "no_valid_tracks", "binary": binary_cleaned, "validated_frame": validated_frame}
            
            # æ­¥éª¤9: é€‰æ‹©æœ€ä½³è½¨è¿¹
            if len(valid_tracks) == 1:
                best_track = valid_tracks[0]
            else:
                # å¤šä¸ªå€™é€‰æ—¶ï¼ŒæŒ‰æ€»è¯„åˆ†æ’åº
                valid_tracks.sort(key=lambda x: x['score'], reverse=True)
                best_track = valid_tracks[0]
                
                # å¦‚æœå­˜åœ¨å‰å‘æ–¹å‘çš„è½¨è¿¹ï¼Œä¼˜å…ˆé€‰æ‹©
                forward_candidates = [track for track in valid_tracks if track['direction_score'] >= 2.5]
                if forward_candidates and best_track['direction_score'] < 2.5:
                    best_forward = max(forward_candidates, key=lambda x: x['score'])
                    if best_forward['score'] >= best_track['score'] * 0.8:
                        best_track = best_forward
            
            contour = best_track['contour']
            
            # æ­¥éª¤10: è®¡ç®—è½¨è¿¹ä¸­å¿ƒå’Œç‰¹å¾
            M = cv2.moments(contour)
            
            if M["m00"] == 0:
                return {"found": False, "reason": "zero_moment", "binary": binary_cleaned, "validated_frame": validated_frame}
            
            # è®¡ç®—è½¨è¿¹ä¸­å¿ƒç‚¹ï¼ˆéœ€è¦åŠ ä¸Šè£å‰ªåç§»ï¼‰
            cx = int(M["m10"] / M["m00"]) + self.crop_margin
            cy = int(M["m01"] / M["m00"]) + self.crop_margin
            
            # è½¨è¿¹æ–¹å‘è§’åº¦
            track_angle = best_track['track_angle']
            
            # è®¡ç®—è½¨è¿¹å®½åº¦
            track_width = min(best_track['width'], best_track['height'])
            track_length = max(best_track['width'], best_track['height'])
            
            # è½¬å¼¯æ£€æµ‹
            points = contour.reshape(-1, 2)
            has_turn = detect_turn_improved(contour, points)
            
            return {
                "found": True,
                "center": (cx, cy),
                "track_angle": float(track_angle),
                "normalized_angle": float(best_track['normalized_angle']),
                "direction_score": float(best_track['direction_score']),
                "track_width": float(track_width),
                "track_length": float(track_length),
                "has_turn": has_turn,
                "contour": contour,
                "binary": binary_cleaned,
                "validated_frame": validated_frame,
                "track_info": best_track,
                "candidates_count": len(valid_tracks),
                "area": best_track['area'],
                "aspect_ratio": best_track['aspect_ratio'],
                "solidity": best_track['solidity']
            }
            
        except Exception as e:
            print(f"ä¼˜åŒ–è½¨è¿¹æ£€æµ‹é”™è¯¯: {e}")
            return {"found": False, "reason": f"error: {e}", "validated_frame": validated_frame}
    
    def detect_track(self, frame):
        """è½¨è¿¹æ£€æµ‹ - ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬"""
        return self.detect_track_optimized(frame)
    
    def calculate_track_following_control(self, track_result):
        """
        è®¡ç®—è½¨è¿¹è·Ÿéšæ§åˆ¶æŒ‡ä»¤ - é‡‡ç”¨linetrack3.pyçš„æ§åˆ¶é€»è¾‘
        """
        if not track_result["found"]:
            return {
                "lr": 0, "fb": 0, "yaw": 15,
                "control_mode": "SEARCHING",
                "status": "no_track",
                "alignment_score": 0
            }
        
        # è·å–è½¨è¿¹ä¿¡æ¯
        track_center = track_result["center"]
        track_angle = track_result["track_angle"]
        track_width = track_result["track_width"]
        has_turn = track_result.get("has_turn", False)
        
        # æ·»åŠ åˆ°é¢„æµ‹å™¨
        self.predictor.add_observation(track_center, track_angle)
        
        # åŸºç¡€ä½ç½®æ§åˆ¶
        position_control = self.coord_system.image_to_drone_control(track_center[0], track_center[1])
        base_lr = position_control['lr']
        base_fb = position_control['fb']
        
        # æ–¹å‘æ§åˆ¶
        yaw_control, angle_error = self.coord_system.calculate_direction_control(track_angle, 0)
        
        # è®¡ç®—å¯¹é½è¯„åˆ†
        position_offset = np.sqrt(position_control['offset_x']**2 + position_control['offset_y']**2)
        alignment_score = max(0, 100 - position_offset * 2 - abs(angle_error))
        
        # æ ¹æ®å¯¹é½æƒ…å†µå†³å®šæ§åˆ¶æ¨¡å¼
        if position_offset <= self.track_alignment_tolerance and abs(angle_error) <= self.direction_threshold:
            # å®Œç¾å¯¹é½
            control_mode = "ALIGNED_FORWARD"
            
            # é¢„æµ‹æ€§æ§åˆ¶
            predicted_pos = self.predictor.predict_next_position()
            if predicted_pos:
                future_control = self.coord_system.image_to_drone_control(predicted_pos[0], predicted_pos[1])
                final_lr = int(base_lr * 0.7 + future_control['lr'] * 0.3)
                final_fb = max(self.min_forward_speed, int(base_fb * 0.5 + self.coord_system.max_forward_speed * 0.8))
            else:
                final_lr = base_lr
                final_fb = max(self.min_forward_speed, self.coord_system.max_forward_speed)
            
            final_yaw = int(yaw_control * 0.6)
            
        elif position_offset <= self.track_alignment_tolerance * 2:
            # åŸºæœ¬å¯¹é½
            control_mode = "FINE_TUNING"
            
            final_lr = int(base_lr * 1.2)
            final_fb = int(self.coord_system.max_forward_speed * 0.7)
            final_yaw = int(yaw_control * 0.8)
            
        elif abs(angle_error) > self.direction_threshold * 2:
            # æ–¹å‘åå·®å¤§
            control_mode = "DIRECTION_CORRECTION"
            
            final_lr = int(base_lr * 0.5)
            final_fb = self.min_forward_speed if abs(angle_error) < 45 else 0
            final_yaw = yaw_control
            
        else:
            # ä½ç½®åå·®å¤§
            control_mode = "POSITION_CORRECTION"
            
            final_lr = base_lr
            final_fb = int(self.coord_system.max_forward_speed * 0.5)
            final_yaw = int(yaw_control * 0.7)
        
        # è½¬å¼¯ç‰¹æ®Šå¤„ç†
        if has_turn:
            if control_mode == "ALIGNED_FORWARD":
                control_mode = "TURN_FOLLOWING"
                final_fb = int(final_fb * 0.6)
                final_yaw = int(final_yaw * 1.3)
            elif abs(angle_error) > 30:
                control_mode = "SHARP_TURN"
                final_fb = 0
                final_yaw = yaw_control
        
        # é™åˆ¶æ§åˆ¶èŒƒå›´
        final_lr = int(np.clip(final_lr, -self.coord_system.max_lateral_speed, self.coord_system.max_lateral_speed))
        final_fb = int(np.clip(final_fb, -self.coord_system.max_forward_speed, self.coord_system.max_forward_speed))
        final_yaw = int(np.clip(final_yaw, -self.coord_system.max_yaw_speed, self.coord_system.max_yaw_speed))
        
        # è¿åŠ¨è¶‹åŠ¿åˆ†æ
        movement_trend = self.predictor.get_movement_trend()
        
        return {
            "lr": final_lr,
            "fb": final_fb,
            "yaw": final_yaw,
            "control_mode": control_mode,
            "alignment_score": alignment_score,
            "position_offset": position_offset,
            "angle_error": angle_error,
            "movement_trend": movement_trend,
            "has_turn": has_turn,
            "track_width": track_width,
            "status": "tracking"
        }
    
    def calculate_control(self, track_result):
        """è®¡ç®—å·¡çº¿æ§åˆ¶æŒ‡ä»¤ - ä½¿ç”¨å¢å¼ºç‰ˆæœ¬"""
        return self.calculate_track_following_control(track_result)
    
    def execute_smart_tracking_control(self, control_result):
        """æ‰§è¡Œæ™ºèƒ½è½¨è¿¹è·Ÿéšæ§åˆ¶"""
        lr = int(control_result["lr"])
        fb = int(control_result["fb"])
        yaw = int(control_result["yaw"])
        
        control_mode = control_result["control_mode"]
        
        if control_mode == "DIRECTION_CORRECTION":
            angle_error = abs(control_result.get("angle_error", 0))
            
            if angle_error > 45:
                # å¤§è§’åº¦ä¿®æ­£ - åˆ†æ­¥æ‰§è¡Œ
                self.single_tello.send_rc_control(0, 0, 0, yaw)
                time.sleep(0.8)
                self.single_tello.send_rc_control(
                    int(lr * 0.5),
                    int(self.min_forward_speed),
                    0,
                    int(yaw * 0.7)
                )
            else:
                self.single_tello.send_rc_control(lr, fb, 0, yaw)
        elif control_mode == "SHARP_TURN":
            # æ€¥è½¬å¼¯ï¼šå…ˆè½¬å‘å†å‰è¿›
            self.single_tello.send_rc_control(0, 0, 0, yaw)
            time.sleep(1.0)
            self.single_tello.send_rc_control(int(lr), int(self.min_forward_speed), 0, 0)
        else:
            # æ­£å¸¸æ§åˆ¶
            self.single_tello.send_rc_control(lr, fb, 0, yaw)
    
    def visualize_tracking(self, frame, track_result, control_result):
        """å¯è§†åŒ–å·¡çº¿çŠ¶æ€ - å¢å¼ºç‰ˆæœ¬"""
        # ä¼˜å…ˆä½¿ç”¨éªŒè¯åçš„å¸§
        if "validated_frame" in track_result and track_result["validated_frame"] is not None:
            working_frame = track_result["validated_frame"]
        elif frame is not None:
            working_frame = self.validate_and_crop_frame(frame)
        else:
            return None
        
        if working_frame is None:
            return None
        
        annotated_frame = working_frame.copy()
        height, width = annotated_frame.shape[:2]
        center_x, center_y = width // 2, height // 2
        
        # æ˜¾ç¤ºåæ ‡ç³»åå­—çº¿
        cv2.line(annotated_frame, (center_x-15, center_y), (center_x+15, center_y), (255, 0, 0), 2)
        cv2.line(annotated_frame, (center_x, center_y-15), (center_x, center_y+15), (255, 0, 0), 2)
        cv2.circle(annotated_frame, (center_x, center_y), 6, (255, 0, 0), -1)
        
        # æ˜¾ç¤ºåæ ‡ç³»ä¿¡æ¯
        cv2.putText(annotated_frame, "Downward View - Left=Forward", 
                   (10, height-80), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
        cv2.putText(annotated_frame, f"Size: {width}x{height}", 
                   (width-100, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
        
        if track_result["found"]:
            # æ ¹æ®æ§åˆ¶æ¨¡å¼é€‰æ‹©é¢œè‰²
            control_mode = control_result["control_mode"]
            alignment_score = control_result["alignment_score"]
            
            if control_mode == "ALIGNED_FORWARD":
                contour_color = (0, 255, 0)  # ç»¿è‰²
                mode_text = "ALIGNED & FORWARD"
            elif control_mode == "FINE_TUNING":
                contour_color = (0, 255, 255)  # é»„è‰²
                mode_text = "FINE TUNING"
            elif control_mode == "DIRECTION_CORRECTION":
                contour_color = (0, 165, 255)  # æ©™è‰²
                mode_text = "DIRECTION CORRECT"
            elif control_mode == "POSITION_CORRECTION":
                contour_color = (255, 0, 255)  # ç´«è‰²
                mode_text = "POSITION CORRECT"
            elif control_mode in ["TURN_FOLLOWING", "SHARP_TURN"]:
                contour_color = (0, 0, 255)  # çº¢è‰²
                mode_text = control_mode
            else:
                contour_color = (128, 128, 128)  # ç°è‰²
                mode_text = control_mode
            
            # ç»˜åˆ¶è½¨è¿¹è½®å»“
            cv2.drawContours(annotated_frame, [track_result["contour"]], -1, contour_color, 3)
            
            # ç»˜åˆ¶è½¨è¿¹ä¸­å¿ƒç‚¹
            track_center = track_result["center"]
            cv2.circle(annotated_frame, track_center, 8, (0, 0, 255), -1)
            cv2.circle(annotated_frame, track_center, 12, (255, 255, 255), 2)
            
            # ç»˜åˆ¶åç§»å‘é‡
            cv2.arrowedLine(annotated_frame, (center_x, center_y), track_center, (255, 255, 0), 2, tipLength=0.3)
            
            # ç»˜åˆ¶è½¨è¿¹æ–¹å‘ç®­å¤´
            track_angle = track_result["track_angle"]
            angle_rad = np.radians(track_angle)
            arrow_length = 60
            
            end_x = int(track_center[0] + arrow_length * np.cos(angle_rad))
            end_y = int(track_center[1] + arrow_length * np.sin(angle_rad))
            cv2.arrowedLine(annotated_frame, track_center, (end_x, end_y), contour_color, 3, tipLength=0.4)
            
            # ç»˜åˆ¶é¢„æµ‹ä½ç½®
            predicted_pos = self.predictor.predict_next_position()
            if predicted_pos and 0 <= predicted_pos[0] < width and 0 <= predicted_pos[1] < height:
                cv2.circle(annotated_frame, predicted_pos, 6, (0, 255, 255), 2)
                cv2.putText(annotated_frame, "PRED", (predicted_pos[0]-15, predicted_pos[1]-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
            
            # ç»˜åˆ¶å¯¹é½è¯„åˆ†æ¡
            score_bar_width = 150
            score_bar_height = 15
            score_bar_x = width - score_bar_width - 10
            score_bar_y = 10
            
            # èƒŒæ™¯æ¡
            cv2.rectangle(annotated_frame, (score_bar_x, score_bar_y), 
                         (score_bar_x + score_bar_width, score_bar_y + score_bar_height), (50, 50, 50), -1)
            
            # åˆ†æ•°æ¡
            score_width = int((alignment_score / 100.0) * score_bar_width)
            score_color = (0, 255, 0) if alignment_score > 80 else (0, 255, 255) if alignment_score > 60 else (0, 165, 255)
            cv2.rectangle(annotated_frame, (score_bar_x, score_bar_y), 
                         (score_bar_x + score_width, score_bar_y + score_bar_height), score_color, -1)
            
            cv2.putText(annotated_frame, f"Alignment: {alignment_score:.0f}%", 
                       (score_bar_x, score_bar_y + score_bar_height + 15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            
            # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            info_lines = [
                f"Mode: {mode_text}",
                f"Position Offset: {control_result['position_offset']:.1f}px",
                f"Angle Error: {control_result['angle_error']:.1f}Â°",
                f"Track Size: {track_result['track_width']:.0f}x{track_result['track_length']:.0f}",
                f"Control: LR={control_result['lr']} FB={control_result['fb']} YAW={control_result['yaw']}"
            ]
            
            for i, text in enumerate(info_lines):
                y_pos = 30 + i * 18
                
                if i == 0:  # æ¨¡å¼
                    color = contour_color
                    thickness = 2
                elif i == 4:  # æ§åˆ¶æŒ‡ä»¤
                    color = (255, 0, 0)
                    thickness = 2
                else:
                    color = (255, 255, 255)
                    thickness = 1
                
                cv2.putText(annotated_frame, text, (10, y_pos), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, thickness)
            
            # æ˜¾ç¤ºè¿åŠ¨è¶‹åŠ¿
            movement_trend = control_result.get("movement_trend", "unknown")
            cv2.putText(annotated_frame, f"Trend: {movement_trend}", 
                       (10, height - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            
            # è½¬å¼¯æŒ‡ç¤º
            if track_result.get("has_turn", False):
                cv2.putText(annotated_frame, "TURN DETECTED!", 
                           (width//2-80, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            
        else:
            # æœªæ£€æµ‹åˆ°è½¨è¿¹
            reason = track_result.get("reason", "unknown")
            cv2.putText(annotated_frame, f"No track detected: {reason}", 
                       (center_x-120, center_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            
            # æ˜¾ç¤ºæœç´¢æ¨¡å¼
            cv2.putText(annotated_frame, "SEARCHING MODE", 
                       (center_x-80, center_y+30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 165, 255), 2)
        
        # æ˜¾ç¤ºæ ‡é¢˜
        cv2.putText(annotated_frame, "Optimized Line Tracking (linetrack3.py algorithm)", 
                   (10, height-20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        
        return annotated_frame
    
    def tracking_worker(self):
        """å·¡çº¿å·¥ä½œçº¿ç¨‹ - å¢å¼ºç‰ˆæœ¬"""
        print("ğŸš å·¡çº¿çº¿ç¨‹å¯åŠ¨ï¼ˆé‡‡ç”¨linetrack3ä¼˜åŒ–ç®—æ³•ï¼‰")
        
        try:
            while self.is_tracking and self.tello_controller.connected:
                # è·å–å½“å‰å¸§
                frame = None
                if self.frame_read:
                    frame = self.frame_read.frame
                
                if frame is not None:
                    # åˆå§‹åŒ–æš—è§’æ ¡æ­£å™¨
                    if self.vignette_corrector is None:
                        self.vignette_corrector = VignetteCorrector(frame.shape, 0.4)
                        print("âœ“ æš—è§’æ ¡æ­£å™¨å·²åˆå§‹åŒ–")
                    
                    # éªŒè¯å›¾åƒå°ºå¯¸
                    original_shape = frame.shape
                    validated_frame = self.validate_and_crop_frame(frame)
                    
                    if validated_frame is not None:
                        self.current_frame = validated_frame.copy()
                        
                        # å¦‚æœå›¾åƒè¢«ä¿®æ­£ï¼Œè®°å½•æ—¥å¿—
                        if validated_frame.shape != original_shape:
                            print(f"ğŸ“ å›¾åƒå·²ä¿®æ­£: {original_shape} -> {validated_frame.shape}")
                        
                        # ä½¿ç”¨ä¼˜åŒ–çš„è½¨è¿¹æ£€æµ‹
                        track_result = self.detect_track_optimized(validated_frame)
                        
                        # ä½¿ç”¨å¢å¼ºçš„æ§åˆ¶è®¡ç®—
                        control_result = self.calculate_track_following_control(track_result)
                        
                        # å¢å¼ºçš„å¯è§†åŒ–
                        annotated_frame = self.visualize_tracking(validated_frame, track_result, control_result)
                        
                        # æ˜¾ç¤ºç»“æœ
                        if annotated_frame is not None:
                            cv2.imshow("Line Tracking", annotated_frame)
                            
                            # æ˜¾ç¤ºäºŒå€¼åŒ–å›¾åƒ
                            if "binary" in track_result:
                                cv2.imshow("Track Binary", track_result["binary"])
                            
                            cv2.waitKey(1)
                        
                        # æ›´æ–°çŠ¶æ€
                        with self.track_lock:
                            self.track_detected = track_result["found"]
                            self.control_mode = control_result["control_mode"]
                            self.alignment_score = control_result["alignment_score"]
                            
                            if track_result["found"]:
                                self.last_track_time = time.time()
                        
                        # æ‰§è¡Œæ™ºèƒ½æ§åˆ¶ï¼ˆä»…åœ¨é£è¡Œæ—¶ï¼‰
                        if self.tello_controller.flying:
                            try:
                                self.execute_smart_tracking_control(control_result)
                            except Exception as e:
                                print(f"æ™ºèƒ½å·¡çº¿æ§åˆ¶å‘é€å¤±è´¥: {e}")
                    else:
                        print("âš  å›¾åƒéªŒè¯å¤±è´¥ï¼Œè·³è¿‡æœ¬å¸§")
                
                time.sleep(0.033)  # çº¦30fps
                
        except Exception as e:
            print(f"å·¡çº¿çº¿ç¨‹é”™è¯¯: {e}")
            traceback.print_exc()
        finally:
            print("ğŸš å·¡çº¿çº¿ç¨‹é€€å‡º")
            cv2.destroyAllWindows()
    
    def start_line_tracking(self):
        """å¯åŠ¨å·¡çº¿æ¨¡å¼ - å¢å¼ºç‰ˆæœ¬"""
        if self.is_tracking:
            print("âš  å·¡çº¿æ¨¡å¼å·²åœ¨è¿è¡Œ")
            return False
        
        if not self.tello_controller.connected:
            print("âŒ Telloæœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨å·¡çº¿")
            return False
        
        try:
            print("ğŸ¥ åˆ‡æ¢åˆ°ä¸‹è§†æ‘„åƒå¤´...")
            self.single_tello.set_video_direction(1)  # ä¸‹è§†æ‘„åƒå¤´
            time.sleep(2)
            
            # å¯åŠ¨è§†é¢‘æµ
            print("ğŸ“¹ å¯åŠ¨è§†é¢‘æµ...")
            self.single_tello.streamon()
            time.sleep(1)
            
            self.frame_read = self.single_tello.get_frame_read()
            time.sleep(1)
            
            # ç­‰å¾…è§†é¢‘æµç¨³å®šå¹¶éªŒè¯å›¾åƒè´¨é‡
            print("ğŸ” éªŒè¯ä¸‹è§†æ‘„åƒå¤´å›¾åƒè´¨é‡...")
            stable_frames = 0
            for i in range(15):
                frame = self.frame_read.frame
                if frame is not None:
                    validated_frame = self.validate_and_crop_frame(frame)
                    if validated_frame is not None and validated_frame.shape[:2] == (self.expected_height, self.expected_width):
                        stable_frames += 1
                        if stable_frames >= 3:
                            print(f"âœ“ ä¸‹è§†æ‘„åƒå¤´å°±ç»ªï¼Œç¨³å®šåˆ†è¾¨ç‡: {validated_frame.shape}")
                            # åˆå§‹åŒ–æš—è§’æ ¡æ­£å™¨
                            self.vignette_corrector = VignetteCorrector(validated_frame.shape, 0.4)
                            print("âœ“ æš—è§’æ ¡æ­£å™¨å·²åˆå§‹åŒ–")
                            break
                    else:
                        stable_frames = 0
                        print(f"âš  å›¾åƒå¼‚å¸¸ï¼Œé‡è¯•... ({i+1}/15)")
                time.sleep(0.5)
            else:
                print("âŒ ä¸‹è§†æ‘„åƒå¤´å›¾åƒè´¨é‡ä¸ç¨³å®šï¼Œä½†ç»§ç»­å°è¯•å¯åŠ¨")
            
            # å¯åŠ¨å·¡çº¿çº¿ç¨‹
            self.is_tracking = True
            self.tracking_thread = threading.Thread(target=self.tracking_worker, daemon=True)
            self.tracking_thread.start()
            
            print("âœ… å·¡çº¿æ¨¡å¼å¯åŠ¨æˆåŠŸï¼ˆé‡‡ç”¨linetrack3.pyä¼˜åŒ–ç®—æ³•ï¼‰")
            return True
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨å·¡çº¿æ¨¡å¼å¤±è´¥: {e}")
            self.is_tracking = False
            return False
    
    def stop_line_tracking(self):
        """åœæ­¢å·¡çº¿æ¨¡å¼"""
        if not self.is_tracking:
            print("âš  å·¡çº¿æ¨¡å¼æœªè¿è¡Œ")
            return
        
        print("ğŸ›‘ åœæ­¢å·¡çº¿æ¨¡å¼...")
        self.is_tracking = False
        
        # åœæ­¢ç§»åŠ¨
        try:
            if self.tello_controller.flying:
                self.single_tello.send_rc_control(0, 0, 0, 0)
        except:
            pass
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.tracking_thread:
            self.tracking_thread.join(timeout=3)
        
        # å…³é—­çª—å£
        cv2.destroyAllWindows()
        
        # åˆ‡æ¢å›å‰è§†æ‘„åƒå¤´
        try:
            print("ğŸ¥ åˆ‡æ¢å›å‰è§†æ‘„åƒå¤´...")
            self.single_tello.set_video_direction(0)
            time.sleep(1)
        except Exception as e:
            print(f"åˆ‡æ¢æ‘„åƒå¤´å¤±è´¥: {e}")
        
        print("âœ… å·¡çº¿æ¨¡å¼å·²åœæ­¢")
    
    def get_tracking_status(self):
        """è·å–å·¡çº¿çŠ¶æ€ - å¢å¼ºç‰ˆæœ¬"""
        with self.track_lock:
            if not self.is_tracking:
                return "æœªå¯åŠ¨"
            elif self.track_detected:
                return f"è·Ÿè¸ªä¸­ | æ¨¡å¼: {self.control_mode} | è¯„åˆ†: {self.alignment_score:.0f}%"
            else:
                lost_time = time.time() - self.last_track_time
                return f"æœç´¢ä¸­ | ä¸¢å¤±: {lost_time:.1f}s"
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.stop_line_tracking()
        print("âœ“ å·¡çº¿æ¨¡å—å·²æ¸…ç†")
